# -*- coding: utf-8 -*-
"""Audio_to_transcript.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kR_570UevteHYlqcCfMmXqOUHVyxZ0NR
"""

!pip install -q git+https://github.com/openai/whisper.git
!pip install -q ffmpeg-python

"""Extracting transcript from the audio.wav files using whisper library

"""

import whisper
import pandas as pd

# Load the model (you can use 'tiny', 'base', 'small', 'medium', or 'large')
model = whisper.load_model("base")

# Path to your .wav file
audio_path = "/content/319_AUDIO.wav"

# Transcribe with word-level timestamps
result = model.transcribe(audio_path, word_timestamps=False)

# Extract segments
segments = result['segments']

# Prepare formatted output
transcript = []
for segment in segments:
    start = round(segment['start'], 1)
    end = round(segment['end'], 1)
    text = segment['text'].strip()
    confidence = round(segment.get('avg_logprob', 0.0), 6)

    # Whisper's logprobs are negative; normalize roughly for readability
    normalized_conf = round(1 + confidence / 5, 9)  # crude transformation for 0~1 scale
    transcript.append([start, end, text, normalized_conf])

# Convert to DataFrame and display
df = pd.DataFrame(transcript, columns=["Start_Time", "End_Time", "Text", "Confidence"])
print(df.to_string(index=False))

df.to_csv("transcript_output.csv", index=False)

from google.colab import files
files.download("transcript_output.csv")