# -*- coding: utf-8 -*-
"""Text_final_modify.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1arCP0rzpQ-sy5sCqjAVAU0Zs-j91D2NU

1) Main model (for multimodal analysis and prediction):
a) speech alone based, b) text alone, c) speech + text, d) face, e) speech + text + face
"""

zip_path = '/content/Transcripts.zip'

import zipfile
import os

extract_path = '/content/Trnacripts_extracted'
os.makedirs(extract_path, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

import os
transcript_path = '/content/Trnacripts_extracted/Transcripts'

# List all CSV files
csv_files = [f for f in os.listdir(transcript_path) if f.endswith('.csv')]

# Example: Read one file using pandas
import pandas as pd
edf = pd.read_csv(os.path.join(transcript_path, csv_files[0]))
print(edf.head())

label_path='/content/detailed_lables.csv'
df1 = pd.read_csv(label_path)
print(df1.head())

df1

train_df = df1
print(train_df.head())

Train_ids = train_df['Participant'].astype(str).tolist()

features = []

import pandas as pd
import os
import re

features = []

for file in csv_files:
    pid = file.split('_')[0]  # Extract ID from filename
    if pid not in Train_ids:
        continue

    df = pd.read_csv(os.path.join(transcript_path, file))

    total_duration = df['End_Time'].max() - df['Start_Time'].min()
    total_utterances = len(df)
    avg_confidence = df['Confidence'].mean()
    total_words = df['Text'].astype(str).str.split().map(len).sum()
    avg_words_per_utterance = total_words / total_utterances

    # Compute pause-related features
    start_times = df['Start_Time'].values
    end_times = df['End_Time'].values
    pauses = start_times[1:] - end_times[:-1]
    avg_pause_duration = pauses.mean() if len(pauses) > 0 else 0
    max_pause_duration = pauses.max() if len(pauses) > 0 else 0

    # Full concatenated text
    full_text = " ".join(df['Text'].astype(str)).lower()
    words = re.findall(r'\b\w+\b', full_text)
    unique_words = len(set(words))
    lexical_diversity = unique_words / total_words if total_words else 0
    avg_word_len = sum(len(w) for w in words) / total_words if total_words else 0

    # Sleep-related keywords
    sleep_keywords = ['sleep', 'tired', 'insomnia', 'rest', 'dream', 'awake', 'nap', 'fatigue']
    sleep_word_count = sum(full_text.count(word) for word in sleep_keywords)

    # Pronoun and negation features
    first_person_pronouns = sum(full_text.count(w) for w in ['i', 'me', 'my'])
    negations = sum(full_text.count(w) for w in ['not', "don’t", "can't", "won’t", "no", "never"])

    features.append({
        'Participant_ID': pid,
        'Total_Duration': total_duration,
        'Total_Utterances': total_utterances,
        'Avg_Confidence': avg_confidence,
        'Total_Words': total_words,
        'Avg_Words_Per_Utterance': avg_words_per_utterance,
        'Avg_Pause_Duration': avg_pause_duration,
        'Max_Pause_Duration': max_pause_duration,
        'Lexical_Diversity': lexical_diversity,
        'Avg_Word_Length': avg_word_len,
        'Sleep_Word_Count': sleep_word_count,
        'First_Person_Pronouns': first_person_pronouns,
        'Negation_Count': negations
    })

features_df = pd.DataFrame(features)
print(features_df.head())

from sklearn.preprocessing import MinMaxScaler

# Select columns to normalize (excluding ID and label)
columns_to_normalize = ['Total_Duration', 'Total_Utterances', 'Avg_Confidence',
                        'Total_Words', 'Avg_Words_Per_Utterance', 'Avg_Pause_Duration',
                        'Max_Pause_Duration', 'Lexical_Diversity', 'Avg_Word_Length',
                        'Sleep_Word_Count', 'First_Person_Pronouns', 'Negation_Count']

# Normalize
scaler = MinMaxScaler()
features_df[columns_to_normalize] = scaler.fit_transform(features_df[columns_to_normalize])

print(features_df.head())

import joblib

# Assuming `scaler` is your fitted StandardScaler or MinMaxScaler
joblib.dump(scaler, 'scaler.pkl')

print(features_df.columns)

from sklearn.feature_extraction.text import CountVectorizer

# Collect all participant transcripts
participant_texts = []

participant_ids = []
for file in csv_files:
    pid = file.split('_')[0]
    if pid not in Train_ids:
        continue

    df = pd.read_csv(os.path.join(transcript_path, file))
    full_text = ' '.join(df['Text'].dropna().astype(str).tolist())
    participant_texts.append(full_text)
    participant_ids.append(pid)

# Create binary Bag of Words model
vectorizer = CountVectorizer(binary=True, max_features=1000)  # limit vocab if needed
X_bow = vectorizer.fit_transform(participant_texts).toarray()

# Create DataFrame
bow_df = pd.DataFrame(X_bow, columns=[f'word_{w}' for w in vectorizer.get_feature_names_out()])
bow_df['Participant_ID'] = participant_ids

# Merge with features_df
#features_df = features_df.merge(bow_df, on='Participant_ID')

bow_df

final_df = bow_df.merge(features_df, on='Participant_ID', how='inner')

final_df_1 = bow_df.merge(features_df, on='Participant_ID', how='inner')

final_df

X = final_df.drop(['Participant_ID'], axis=1)
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Standardize
X_scaled = StandardScaler().fit_transform(X)

# Apply PCA
pca = PCA(n_components=0.95)  # retain 95% variance
X_pca = pca.fit_transform(X_scaled)

# Create new DataFrame with PCA components
pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(X_pca.shape[1])])
pca_df['Participant_ID'] = final_df['Participant_ID'].values


print(pca_df.head())

import numpy as np
train_df
train_df['Sleep_Disorder'] = np.where((train_df['PHQ8_3_Sleep'] >= 2) & (train_df['PCL-C_13_Sleep'] >= 3), 1, 0)
train_df.loc[(train_df['PHQ8_3_Sleep'] == 3) | (train_df['PCL-C_13_Sleep'] >= 4), 'Sleep_Disorder'] = 1

final_df=pca_df
pca_df

print(final_df.columns)

train_df = train_df.loc[:, ~train_df.columns.duplicated()]

# Remove duplicate column names if any
train_df = train_df.rename(columns={'Participant': 'Participant_ID'})
train_df = train_df.loc[:, ~train_df.columns.duplicated()]

# Ensure both Participant_ID columns are strings
final_df['Participant_ID'] = final_df['Participant_ID'].astype(str)
train_df['Participant_ID'] = train_df['Participant_ID'].astype(str)

# Merge
# Remove duplicate column names
final_df = final_df.loc[:, ~final_df.columns.duplicated()]

# Now safely subset and merge
final_df = final_df.merge(train_df[['Participant_ID', 'PHQ8_3_Sleep']], on='Participant_ID', how='inner')

df1

final_df = final_df.merge(train_df[['Participant_ID', 'split','PTSD_severity','Depression_severity','Sleep_Disorder']], on='Participant_ID', how='inner')

final_df

test_df = final_df[final_df['split'] == 'test']
print(test_df.head())

train = final_df[final_df['split'].isin(['train', 'dev'])]
print(train.head())

train

"""Binary"""

# Drop 'Participant_ID', 'PHQ8_3_Sleep', and 'split' columns
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

X_train = train.drop(['Participant_ID', 'PHQ8_3_Sleep', 'split','Sleep_Disorder','Depression_severity','PTSD_severity'], axis=1)
X_test = test_df.drop(['Participant_ID', 'PHQ8_3_Sleep', 'split','Sleep_Disorder','Depression_severity','PTSD_severity'], axis=1)
y_train = train['Sleep_Disorder']
y_test = test_df['Sleep_Disorder']

# Train
model = XGBClassifier(objective='multi:softmax', num_class=2, eval_metric='mlogloss')
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluate
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Get feature importances from the XGBoost model
importances = model.feature_importances_

# If X_train is a sparse matrix (like from CountVectorizer or TfidfVectorizer), convert to array
if hasattr(X_train, 'toarray'):
    X_train_array = X_train.toarray()
    feature_names = vectorizer.get_feature_names_out()  # replace with your vectorizer variable
else:
    feature_names = X_train.columns  # if it's a DataFrame

# Create DataFrame of feature importances
feature_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
})

# Sort and select top N
top_n = 20
top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(top_n)

# Plot and save
plt.figure(figsize=(10, 8))
sns.barplot(x='Importance', y='Feature', data=top_features)
plt.title(f"Top {top_n} Most Important Features (XGBoost)")
plt.tight_layout()
plt.savefig("xgb_top_features_importance.png", dpi=300)
plt.show()

# Assuming you used this earlier:
pca = PCA(n_components=0.95)
pca.fit(X_scaled)

# Get feature names (make sure they match your original features)
feature_names = final_df_1.drop(['Participant_ID'], axis=1).columns

fname=feature_names

final_df_1

import pandas as pd

def get_top_features_for_pc(pca, feature_names, pc_index, top_n=10):
    # Get loadings for the desired PC
    component_loadings = pca.components_[pc_index]
    feature_contributions = pd.DataFrame({
        'Feature': feature_names,
        'Loading': component_loadings
    })
    # Sort by absolute loading value
    top_features = feature_contributions.reindex(
        feature_contributions.Loading.abs().sort_values(ascending=False).index
    ).head(top_n)
    return top_features

print("Number of features in X_scaled:", X_scaled.shape[1])
print("Number of feature names:", len(fname))

pcs_to_check = [80, 64, 76, 106]  # Adjusted for 0-based indexing
top_n = 10

for pc_index in pcs_to_check:
    print(f"\nTop features for PC{pc_index+1}:")
    print(get_top_features_for_pc(pca, feature_names, pc_index, top_n))

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(class_weight='balanced', random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification  # for example

# Replace with your actual data
# X, y = your full features and labels
model = RandomForestClassifier(class_weight='balanced', random_state=42)
X = final_df.drop(['Participant_ID', 'PHQ8_3_Sleep', 'split','Sleep_Disorder','Depression_severity','PTSD_severity'], axis=1)
y = final_df['Sleep_Disorder']
# Cross-validation over the entire dataset
scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print(f"Cross-validated accuracy: {scores.mean():.4f} ± {scores.std():.4f}")

from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

X_train = train.drop(['Participant_ID', 'PHQ8_3_Sleep', 'split','Sleep_Disorder','Depression_severity','PTSD_severity'], axis=1)
X_test = test_df.drop(['Participant_ID', 'PHQ8_3_Sleep', 'split','Sleep_Disorder','Depression_severity','PTSD_severity'], axis=1)
y_train = train['Sleep_Disorder']
y_test = test_df['Sleep_Disorder']
model = DecisionTreeClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

import joblib

# Save model
joblib.dump(model, 'decision_tree_model.pkl')

# Load model later
# model = joblib.load('decision_tree_model.pkl')

"""Multiclasses"""

X_train = train.drop(['Participant_ID', 'PHQ8_3_Sleep', 'split','Sleep_Disorder','Depression_severity','PTSD_severity'], axis=1)
X_test = test_df.drop(['Participant_ID', 'PHQ8_3_Sleep', 'split','Sleep_Disorder','Depression_severity','PTSD_severity'], axis=1)
y_train = train['PHQ8_3_Sleep']
y_test = test_df['PHQ8_3_Sleep']

X_train = X_train.dropna()  # Drop rows with NaN in training data
X_test = X_test.dropna()    # Drop rows with NaN in test data
y_train = y_train[X_train.index]  # Align y_train with dropped rows
y_test = y_test[X_test.index]    # Align y_test with dropped rows

y_test

from sklearn.ensemble import VotingClassifier

ensemble = VotingClassifier(
    estimators=[('dt', DecisionTreeClassifier()), ('xgb', XGBClassifier()), ('lr', LogisticRegression(max_iter=1000))],
    voting='soft'
)
ensemble.fit(X_train, y_train)

# Predict on test data
y_pred = ensemble.predict(X_test)

# Evaluate performance
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

from sklearn.utils.class_weight import compute_sample_weight
from xgboost import XGBClassifier

# First, compute sample weights
sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)

# Now fit with sample weights
model = XGBClassifier(
    n_estimators=200,
    max_depth=7,
    learning_rate=0.05,
    objective='multi:softprob',  # Important for multiclass
    num_class=4                  # 4 classes: 0, 1, 2, 3
)

model.fit(X_train, y_train, sample_weight=sample_weights)

# Prediction
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")

X_train

from sklearn.ensemble import HistGradientBoostingClassifier

model = HistGradientBoostingClassifier()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

import joblib

# Save the model
joblib.dump(model, 'hist_gradient_boosting_text_multi.pkl')

# Load the model later (when needed)
# model = joblib.load('hist_gradient_boosting_model.pkl')

final_df = final_df.loc[:, ~final_df.columns.duplicated()]

final_df

"""Prediction of Depression using Text analysis"""

if 'Participant_ID' in final_df.columns and 'Participant_ID' in train_df.columns:
    final_df = final_df.reset_index().merge(train_df[['Participant_ID', 'Depression_label']], on='Participant_ID', how='inner').set_index('index')
    print("Merge successful!")
else:
    print("Error: 'Participant_ID' column not found in one or both DataFrames.")
    # You can add further debugging here, like printing the columns of each DataFrame
    # print("final_df columns:", final_df.columns)
    # print("train_df columns:", train_df.columns)

test_df = final_df[final_df['split'] == 'test']
print(test_df.head())

train = final_df[final_df['split'].isin(['train', 'dev'])]
print(train.head())

# Drop 'Participant_ID', 'PHQ8_3_Sleep', and 'split' columns
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

X_traind = train.drop(['Participant_ID', 'PHQ8_3_Sleep', 'split','Sleep_Disorder','Depression_label','Depression_severity','PTSD_severity'], axis=1)
X_testd = test_df.drop(['Participant_ID', 'PHQ8_3_Sleep', 'split','Sleep_Disorder','Depression_label','Depression_severity','PTSD_severity'], axis=1)
y_traind = train['Depression_label']
y_testd = test_df['Depression_label']

# Train
model = XGBClassifier(objective='multi:softmax', num_class=2, eval_metric='mlogloss')
model.fit(X_traind, y_traind)

# Predict
y_predd = model.predict(X_testd)

# Evaluate
print(classification_report(y_testd, y_predd))
print(confusion_matrix(y_testd, y_predd))

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Get feature importances from the XGBoost model
importances = model.feature_importances_

# If X_train is a sparse matrix (like from CountVectorizer or TfidfVectorizer), convert to array
if hasattr(X_train, 'toarray'):
    X_train_array = X_train.toarray()
    feature_names = vectorizer.get_feature_names_out()  # replace with your vectorizer variable
else:
    feature_names = X_train.columns  # if it's a DataFrame

# Create DataFrame of feature importances
feature_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
})

# Sort and select top N
top_n = 20
top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(top_n)

# Plot and save
plt.figure(figsize=(10, 8))
sns.barplot(x='Importance', y='Feature', data=top_features)
plt.title(f"Top {top_n} Most Important Features (XGBoost)")
plt.tight_layout()
plt.savefig("xgb_top_features_importance.png", dpi=300)
plt.show()

pcs_to_check = [54, 72, 162, 198]  # Adjusted for 0-based indexing
top_n = 10

for pc_index in pcs_to_check:
    print(f"\nTop features for PC{pc_index+1}:")
    print(get_top_features_for_pc(pca, fname, pc_index, top_n))

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(X_traind, y_traind)
y_predd = model.predict(X_testd)

print(classification_report(y_testd, y_predd))
print(confusion_matrix(y_testd, y_predd))

from sklearn.ensemble import HistGradientBoostingClassifier

model = HistGradientBoostingClassifier()
model.fit(X_traind, y_traind)
y_predd = model.predict(X_testd)

print(classification_report(y_testd, y_predd))
print(confusion_matrix(y_testd, y_predd))

joblib.dump(model, 'hist_gradient_boosting_model_depression_binary.pkl')